---
title: Instructions
nav_order: 2
has_children: true
---

# 🛠️ Instructions

**FastFlowLM** is a deeply optimized runtime for **local LLM inference on AMD NPUs** —  
ultra-fast, power-efficient, and 100% offline.

Its user interface and workflow are similar to **Ollama**, but purpose-built for AMD's XDNA2 architecture.  
This sect